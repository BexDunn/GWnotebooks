{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is :0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#Dask_Wetness.py\n",
    "\n",
    "''' \n",
    "Dask_Wetness.py loads surface reflectance data from the data cube, calculates \n",
    "tasselled cap indices, and outputs a netcdf file. It uses dask to keep memory use low.\n",
    "--It requires a PBS submission script to provide i, the polygon number to ingest.\n",
    "Created by Bex Dunn 08/05/2017\n",
    "'''\n",
    "#for writing to error files:\n",
    "from __future__ import print_function\n",
    "#get some libraries\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "import json\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import shape\n",
    "import numpy as np #need this for pq fuser\n",
    "\n",
    "#libraries for polygon and polygon mask\n",
    "import fiona\n",
    "import shapely.geometry\n",
    "import rasterio.features\n",
    "import rasterio\n",
    "from datacube.utils import geometry\n",
    "from datacube.storage.masking import mask_invalid_data\n",
    "\n",
    "#for writing to netcdf\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "#dealing with system commands\n",
    "import sys\n",
    "\n",
    "#suppress warnings thrown when using inequalities in numpy (the threshold values!)\n",
    "import warnings\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "#save netcdf outputs to this folder:\n",
    "netcdf_output_loc ='/g/data/r78/rjd547/groundwater_activities/Burdekin_Results/TCI/burdekin_dam/'\n",
    "\n",
    "#code to work with a polygon input rather than a lat/long box\n",
    "# #pick a shape file\n",
    "shape_file = ('/g/data/r78/rjd547/groundwater_activities/Burdekin_shapefiles/burd_dam/burd_dam_noZ.shp')\n",
    "# open all the shapes within the shape file\n",
    "shapes = fiona.open(shape_file)\n",
    "\n",
    "#i is the number of the polygon within the shapefile that the script will run for.\n",
    "#the next line takes i as a system argument input eg. $Dask_Wetness.py $1\n",
    "#We have to minus one here because python counts from 0 and bash counts from one, therefore\n",
    "#node 1 will be polygon 0.\n",
    "\n",
    "#i=int(sys.argv[1])-1 \n",
    "i=0\n",
    "print('i is :'+str(i))\n",
    "#if we have requested an i greater than the amount of polygons in the file, just print an error message\n",
    "#exit with success condition (0) not failure condition (anything else)\n",
    "if i > len(shapes):\n",
    "    print('index not in the range for the shapefile: '+str(i)+' not in '+str(len(shapes)))\n",
    "    sys.exit(0)\n",
    "\n",
    "#copy attributes from shapefile and define shape_name\n",
    "geom_crs = geometry.CRS(shapes.crs_wkt)\n",
    "geo = shapes[i]['geometry']\n",
    "geom = geometry.Geometry(geo, crs=geom_crs)\n",
    "geom_bs = shapely.geometry.shape(shapes[i]['geometry'])\n",
    "shape_name = shape_file.split('/')[-1].split('.')[0]+'_'+str(i)\n",
    "\n",
    "#geom.boundingbox\n",
    "#using a spatial query while testing the size of the bounding box we can use while running dask #FIXME\n",
    "spatial_q = {\n",
    "    'x': (geom.boundingbox.left, geom.boundingbox.right), \n",
    "    'y': (geom.boundingbox.top, geom.boundingbox.bottom),\n",
    "    'crs': geom.crs.wkt,\n",
    "    }\n",
    "#spatial_q\n",
    "\n",
    "import dask\n",
    "dask.set_options(get=dask.get)\n",
    "\n",
    "#tell the datacube which app to use\n",
    "dc = datacube.Datacube(app='dc-nbar')\n",
    "\n",
    "#### DEFINE SPATIOTEMPORAL RANGE AND BANDS OF INTEREST\n",
    "#Define temporal range\n",
    "start_of_epoch = '1987-01-01'\n",
    "#need a variable here that defines a rolling 'latest observation'\n",
    "end_of_epoch =  '2016-12-31'\n",
    "\n",
    "#Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "bands_of_interest = ['blue',\n",
    "                     'green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1', \n",
    "                     'swir2'\n",
    "                     ]\n",
    "\n",
    "#Define sensors of interest\n",
    "sensor1 = 'ls5'\n",
    "sensor2 = 'ls7'\n",
    "sensor3 = 'ls8'\n",
    "\n",
    "query = {\n",
    "    'time': (start_of_epoch, end_of_epoch), # 'geopolygon': geom\n",
    "    'dask_chunks': {'time': 5},\n",
    "}\n",
    "query.update(spatial_q)\n",
    "\n",
    "#Group PQ by solar day to avoid idiosyncracies of N/S overlap differences in PQ algorithm performance\n",
    "pq_albers_product = dc.index.products.get_by_name(sensor1+'_pq_albers')\n",
    "valid_bit = pq_albers_product.measurements['pixelquality']['flags_definition']['contiguous']['bits']\n",
    "\n",
    "def pq_fuser(dest, src):\n",
    "    valid_val = (1 << valid_bit)\n",
    "\n",
    "    no_data_dest_mask = ~(dest & valid_val).astype(bool)\n",
    "    np.copyto(dest, src, where=no_data_dest_mask)\n",
    "\n",
    "    both_data_mask = (valid_val & dest & src).astype(bool)\n",
    "    np.copyto(dest, src & dest, where=both_data_mask)\n",
    "\n",
    "wetness_coeff = {}\n",
    "wetness_coeff['ls5'] = (0.151, 0.179, 0.330, 0.341, -0.711, -0.457)\n",
    "wetness_coeff['ls7'] = (0.151, 0.179, 0.330, 0.341, -0.711, -0.457)\n",
    "#wetness_coeff['ls7'] = (0.2626, 0.2141, 0.0926, 0.0656, -0.7629, -0.5388)\n",
    "wetness_coeff['ls8'] = (0.1511, 0.1973, 0.3283, 0.3407, -0.7117, -0.4559)\n",
    "\n",
    "\n",
    "## PQ and Index preparation\n",
    "# retrieve the NBAR and PQ for the spatiotemporal range of interest\n",
    "#Retrieve the NBAR and PQ data for sensor n\n",
    "sensor1_nbar = dc.load(product= sensor1+'_nbart_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "sensor1_pq = dc.load(product= sensor1+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)\n",
    "           \n",
    "crs = sensor1_nbar.crs\n",
    "crswkt = sensor1_nbar.crs.wkt\n",
    "affine = sensor1_nbar.affine\n",
    "\n",
    "#Generate PQ masks and apply those masks to remove cloud, cloud shadow, saturated observations\n",
    "s1_cloud_free = masking.make_mask(sensor1_pq, \n",
    "                              cloud_acca='no_cloud',\n",
    "                              cloud_shadow_acca = 'no_cloud_shadow',\n",
    "                              cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                              cloud_fmask='no_cloud',\n",
    "                              blue_saturated = False,\n",
    "                              green_saturated = False,\n",
    "                              red_saturated = False,\n",
    "                              nir_saturated = False,\n",
    "                              swir1_saturated = False,\n",
    "                              swir2_saturated = False,\n",
    "                              contiguous=True)\n",
    "s1_good_data = s1_cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "sensor1_nbar = sensor1_nbar.where(s1_good_data)\n",
    "sensor1_nbar.attrs['crs'] = crs\n",
    "sensor1_nbar.attrs['affine'] = affine\n",
    "\n",
    "sensor2_nbar = dc.load(product= sensor2+'_nbart_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "sensor2_pq = dc.load(product= sensor2+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)                  \n",
    "\n",
    "s2_cloud_free = masking.make_mask(sensor2_pq, \n",
    "                              cloud_acca='no_cloud',\n",
    "                              cloud_shadow_acca = 'no_cloud_shadow',\n",
    "                              cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                              cloud_fmask='no_cloud',\n",
    "                              blue_saturated = False,\n",
    "                              green_saturated = False,\n",
    "                              red_saturated = False,\n",
    "                              nir_saturated = False,\n",
    "                              swir1_saturated = False,\n",
    "                              swir2_saturated = False,\n",
    "                              contiguous=True)\n",
    "s2_good_data = s2_cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "sensor2_nbar = sensor2_nbar.where(s2_good_data)\n",
    "sensor2_nbar.attrs['crs'] = crs\n",
    "sensor2_nbar.attrs['affine'] = affine\n",
    "\n",
    "sensor3_nbar = dc.load(product= sensor3+'_nbart_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "sensor3_pq = dc.load(product= sensor3+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)                  \n",
    "\n",
    "s3_cloud_free = masking.make_mask(sensor3_pq, \n",
    "                              cloud_acca='no_cloud',\n",
    "                              cloud_shadow_acca = 'no_cloud_shadow',\n",
    "                              cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                              cloud_fmask='no_cloud',\n",
    "                              blue_saturated = False,\n",
    "                              green_saturated = False,\n",
    "                              red_saturated = False,\n",
    "                              nir_saturated = False,\n",
    "                              swir1_saturated = False,\n",
    "                              swir2_saturated = False,\n",
    "                              contiguous=True)\n",
    "s3_good_data = s3_cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "sensor3_nbar = sensor3_nbar.where(s3_good_data)\n",
    "sensor3_nbar.attrs['crs'] = crs\n",
    "sensor3_nbar.attrs['affine'] = affine\n",
    "\n",
    "#nbar_clean = xr.concat([sensor1_nbar, sensor2_nbar, sensor3_nbar], dim='time')\n",
    "\n",
    "#Calculate Taselled Cap Wetness\n",
    "wetness_sensor1_nbar = ((sensor1_nbar.blue*wetness_coeff[sensor1][0])+\n",
    "                        (sensor1_nbar.green*wetness_coeff[sensor1][1])+\n",
    "                        (sensor1_nbar.red*wetness_coeff[sensor1][2])+\n",
    "                        (sensor1_nbar.nir*wetness_coeff[sensor1][3])+\n",
    "                        (sensor1_nbar.swir1*wetness_coeff[sensor1][4])+\n",
    "                        (sensor1_nbar.swir2*wetness_coeff[sensor1][5])\n",
    "                       )\n",
    "wetness_sensor2_nbar = ((sensor2_nbar.blue*wetness_coeff[sensor2][0])+(sensor2_nbar.green*wetness_coeff[sensor2][1])+\n",
    "                          (sensor2_nbar.red*wetness_coeff[sensor2][2])+(sensor2_nbar.nir*wetness_coeff[sensor2][3])+\n",
    "                          (sensor2_nbar.swir1*wetness_coeff[sensor2][4])+(sensor2_nbar.swir2*wetness_coeff[sensor2][5]))\n",
    "wetness_sensor3_nbar = ((sensor3_nbar.blue*wetness_coeff[sensor3][0])+(sensor3_nbar.green*wetness_coeff[sensor3][1])+\n",
    "                          (sensor3_nbar.red*wetness_coeff[sensor3][2])+(sensor3_nbar.nir*wetness_coeff[sensor3][3])+\n",
    "                          (sensor3_nbar.swir1*wetness_coeff[sensor3][4])+(sensor3_nbar.swir2*wetness_coeff[sensor3][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/dask/array/core.py:2544: RuntimeWarning: invalid value encountered in greater\n",
      "  return function(*args2, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (y: 1649, x: 1426)>\n",
       "array([[  2,   2,   2, ...,   1,   2,   3],\n",
       "       [  2,   2,   1, ...,   1,   2,   2],\n",
       "       [  2,   2,   3, ...,   3,   3,   4],\n",
       "       ..., \n",
       "       [273, 269, 269, ...,   1,   0,   1],\n",
       "       [272, 272, 269, ...,   1,   0,   2],\n",
       "       [273, 275, 272, ...,   1,   1,   2]])\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.288e+06 -2.288e+06 -2.288e+06 -2.288e+06 ...\n",
       "  * x        (x) float64 1.534e+06 1.534e+06 1.534e+06 1.534e+06 1.534e+06 ..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for wetness_sensor1_nbar, filter, count, and load.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    water_plus_wetveg_1 = wetness_sensor1_nbar.where(wetness_sensor1_nbar>-400)\n",
    "\n",
    "#count the number of wetness scenes for each pixel\n",
    "wet_count_1 = wetness_sensor1_nbar.count(dim='time')\n",
    "\n",
    "#count the amount of times that water plus wet veg is above the threshold\n",
    "threshold_count_1= water_plus_wetveg_1.count(dim='time')\n",
    "\n",
    "#bring both counts into memory \n",
    "wet_count_1.load()\n",
    "threshold_count_1.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/dask/array/core.py:2544: RuntimeWarning: invalid value encountered in greater\n",
      "  return function(*args2, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (y: 1649, x: 1426)>\n",
       "array([[  4,   4,   2, ...,   0,   0,   0],\n",
       "       [  5,   4,   2, ...,   0,   0,   0],\n",
       "       [  5,   3,   3, ...,   1,   0,   1],\n",
       "       ..., \n",
       "       [211, 209, 208, ...,   3,   3,   3],\n",
       "       [215, 214, 213, ...,   1,   3,   3],\n",
       "       [216, 214, 215, ...,   2,   1,   2]])\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.288e+06 -2.288e+06 -2.288e+06 -2.288e+06 ...\n",
       "  * x        (x) float64 1.534e+06 1.534e+06 1.534e+06 1.534e+06 1.534e+06 ..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for wetness_sensor2_nbar, filter, count, and load.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    water_plus_wetveg_2 = wetness_sensor2_nbar.where(wetness_sensor2_nbar>-400)\n",
    "#print(water_plus_wetveg_2)\n",
    "\n",
    "#count the number of wetness scenes for each pixel\n",
    "wet_count_2 = wetness_sensor2_nbar.count(dim='time')\n",
    "\n",
    "#count the amount of times that water plus wet veg is above the threshold\n",
    "threshold_count_2= water_plus_wetveg_2.count(dim='time')\n",
    "\n",
    "#bring both counts into memory\n",
    "wet_count_2.load()\n",
    "threshold_count_2.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/dask/array/core.py:2544: RuntimeWarning: invalid value encountered in greater\n",
      "  return function(*args2, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (y: 1649, x: 1426)>\n",
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  1, ...,  0,  0,  1],\n",
       "       ..., \n",
       "       [59, 58, 58, ...,  0,  0,  1],\n",
       "       [59, 59, 58, ...,  0,  0,  0],\n",
       "       [59, 59, 59, ...,  0,  0,  0]])\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.288e+06 -2.288e+06 -2.288e+06 -2.288e+06 ...\n",
       "  * x        (x) float64 1.534e+06 1.534e+06 1.534e+06 1.534e+06 1.534e+06 ..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for wetness_sensor3_nbar, filter, count, and load.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    water_plus_wetveg_3 = wetness_sensor3_nbar.where(wetness_sensor3_nbar>-400)\n",
    "#print(water_plus_wetveg_3)\n",
    "\n",
    "#count the number of wetness scenes for each pixel\n",
    "wet_count_3 = wetness_sensor3_nbar.count(dim='time')\n",
    "\n",
    "#count the amount of times that water plus wet veg is above the threshold\n",
    "threshold_count_3= water_plus_wetveg_3.count(dim='time')\n",
    "\n",
    "#bring both counts into memory\n",
    "wet_count_3.load()\n",
    "threshold_count_3.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #divide the number of times wetness is seen by the number of wetness scenes to get a proportion of time that the \n",
    "# #pixel is wet or wet veg'd:\n",
    "threshold_allsensors = threshold_count_1+threshold_count_2+threshold_count_3\n",
    "wet_count_allsensors = wet_count_1+ wet_count_2+ wet_count_3\n",
    "\n",
    "# #divide the number of times wetness is seen by the number of wetness scenes to get a proportion of time that the \n",
    "# #pixel is wet or wet veg'd:\n",
    "wet_proportion_allsensors= threshold_allsensors/wet_count_allsensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #divide the number of times wetness is seen by the number of wetness scenes to get a proportion of time that the \n",
    "# #pixel is wet or wet veg'd:\n",
    "# wet_proportion_1 = threshold_count_1/wet_count_1\n",
    "\n",
    "# #load wet_proportion_1 into memory before concatenating into the final array to save to netCDF\n",
    "# WP1 = wet_proportion_1.load()\n",
    "\n",
    "#divide the number of times wetness is seen by the number of wetness scenes to get a proportion of time that the \n",
    "#pixel is wet or wet veg'd:\n",
    "#wet_proportion_3 = threshold_count_3/wet_count_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wet_proportion_allsensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn array into dataset so we can write the netcdf\n",
    "dataset_tcw = wet_proportion_allsensors.to_dataset(name='tcw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grab our crs attributes to write a spatially-referenced netcdf\n",
    "dataset_tcw.attrs['crs'] =  sensor1_nbar.crs\n",
    "dataset_tcw.tcw.attrs['crs'] =  sensor1_nbar.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: Storage Unit already exists: /g/data/r78/rjd547/groundwater_activities/Burdekin_Results/TCI/burdekin_dam/burd_dam_noZ_0.nc\n",
      "successfully ran TCI for burd_dam_noZ_0 polygon number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "successfully ran TCI for burd_dam_noZ_0 polygon number 0\n"
     ]
    }
   ],
   "source": [
    "filename = netcdf_output_loc+shape_name+'.nc'\n",
    "try:\n",
    "    write_dataset_to_netcdf(dataset_tcw, filename)\n",
    "except RuntimeError as err:\n",
    "    print(\"RuntimeError: {0}\".format(err))\n",
    "    \n",
    "print('successfully ran TCI for '+shape_name+' polygon number '+str(i))\n",
    "eprint('successfully ran TCI for '+shape_name+' polygon number '+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_tcw.to_netcdf('~/tcw.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
