{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hovmoller plots from shapefile of transects\n",
    "\n",
    "This notebook opens a shape file of transects and plots a hovmoller diagram for each lased on datacube landsat surface reflectance data and BoM rainfall data.\n",
    "\n",
    "* if the time period you wish to plot has changed then you will need to re-save the data manually by changing 'savepath' so that files are not overwritten\n",
    "* if your shapefile is not in Albers you will need to change coordinate reference system specs.\n",
    "* rainfall data is currently in WGS84 due to datacube issues. This isn't a problem at the moment but could be later.\n",
    "* if running for a time period where one of the sensors is not available, you may need to comment out statements referring to that sensor\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "  * shapefile of the site transects in EPSG 3577/Australian Albers\n",
    "  \n",
    "  \n",
    "The following sensors are available for the following time frames:\n",
    "* Landsat 5 - 1986 to April 1999  followed by a gap until May 2003 - November 2011 (data from 2009 onwards becomes less reliable in southern Australia)\n",
    "* Landsat 7 - April 1999 to present, however after May 2003 the scan line corrector (SLC) failed, \n",
    "so data are referred to as SLC-off, meaning they've got a venetian blinds appearance with wedges of missing data\n",
    "  * This data is not well suited for inclusion in composites, but is fine to use in time series analysis\n",
    "* Landsat 8 - April 2013 onwards\n",
    "  \n",
    "Bex Dunn april 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in this notebook we want to plot non-interactively\n",
    "%matplotlib inline\n",
    "\n",
    "#get a bunch of modules to use\n",
    "\n",
    "#suppress warnings thrown when rainfall data is imported\n",
    "import logging\n",
    "logging.getLogger('rasterio._gdal').setLevel(logging.ERROR)\n",
    "import warnings\n",
    "\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from shapely.geometry import shape\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "#libraries for polygon and polygon mask\n",
    "import fiona\n",
    "import shapely.geometry\n",
    "import rasterio.features\n",
    "from datacube.utils import geometry\n",
    "from datacube.helpers import ga_pq_fuser as pq_fuser\n",
    "from datacube.storage.masking import mask_valid_data as mask_invalid_data\n",
    "import rasterio\n",
    "#tells the datacube what app you are planning on using\n",
    "dc = datacube.Datacube(app='dc-BOMRainfallandNbar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up functions for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This defines the function that converts a linear vector file into a string of x,y coordinates\n",
    "def geom_query(geom, geom_crs='EPSG:3577'):\n",
    "    \"\"\"\n",
    "    Create datacube query snippet for geometry\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'x': (geom.bounds[0], geom.bounds[2]),\n",
    "        'y': (geom.bounds[1], geom.bounds[3]),\n",
    "        'crs': geom_crs\n",
    "    }\n",
    "\n",
    "\n",
    "def warp_geometry(geom, crs_crs, dst_crs):\n",
    "    \"\"\"\n",
    "    warp geometry from crs_crs to dst_crs\n",
    "    \"\"\"\n",
    "    return shapely.geometry.shape(rasterio.warp.transform_geom(crs_crs, dst_crs, shapely.geometry.mapping(geom)))\n",
    "\n",
    "\n",
    "def transect(data, geom, resolution, method='nearest', tolerance=None):\n",
    "    \"\"\"\n",
    "    gets the transect\n",
    "    \"\"\"\n",
    "    #Changed for py3 compatibility 17.03.17\n",
    "    dist = [i for i in range(0, int(geom.length), resolution)]\n",
    "    #points = zip(*[geom.interpolate(d).coords[0] for d in dist]) py2\n",
    "    points = list(zip(*[geom.interpolate(d).coords[0] for d in dist])) #py3\n",
    "    indexers = {\n",
    "        data.crs.dimensions[0]: list(points[1]),\n",
    "        data.crs.dimensions[1]: list(points[0])        \n",
    "    }\n",
    "    return data.sel_points(xr.DataArray(dist, name='distance', dims=['distance']),\n",
    "                           method=method,\n",
    "                           tolerance=tolerance,\n",
    "                           **indexers)\n",
    "\n",
    "#mask to use with our polygons to calculate wet and dry years \n",
    "#(comes from http://agdc-v2.readthedocs.io/en/stable/user/guide.html#code-recipes)\n",
    "def geometry_mask(geoms, geobox, all_touched=False, invert=False):\n",
    "    \"\"\"\n",
    "    Create a mask from shapes.\n",
    "\n",
    "    By default, mask is intended for use as a\n",
    "    numpy mask, where pixels that overlap shapes are False.\n",
    "    :param list[Geometry] geoms: geometries to be rasterized\n",
    "    :param datacube.utils.GeoBox geobox:\n",
    "    :param bool all_touched: If True, all pixels touched by geometries will be burned in. If\n",
    "                             false, only pixels whose center is within the polygon or that\n",
    "                             are selected by Bresenham's line algorithm will be burned in.\n",
    "    :param bool invert: If True, mask will be True for pixels that overlap shapes.\n",
    "    \"\"\"\n",
    "    return rasterio.features.geometry_mask([geom.to_crs(geobox.crs) for geom in geoms],\n",
    "                                           out_shape=geobox.shape,\n",
    "                                           transform=geobox.affine,\n",
    "                                           all_touched=all_touched,\n",
    "                                           invert=invert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add the path to the input shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transects file will be the file containing our transects\n",
    "transects_file = '/g/data1/r78/rjd547/groundwater_activities/GalileeBasin/shapefiles/landsat_transects_Galilee_BA.shp'\n",
    "transects_df = gpd.read_file(transects_file)\n",
    "#print(transects_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal range is 1987-10-01 to 2016-10-01\n"
     ]
    }
   ],
   "source": [
    "#Define temporal range - testing with one year of data\n",
    "start_of_epoch = '1987-10-01'\n",
    "#need a variable here that defines a rolling 'latest observation'  \n",
    "end_of_epoch =  '2016-10-01'\n",
    "print ('temporal range is '+start_of_epoch+' to '+end_of_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up wavelengths/bands/sensors/TSS and brightness adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "bands_of_interest = ['blue',\n",
    "                     'green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1', \n",
    "                     'swir2'\n",
    "                     ]\n",
    "\n",
    "#Define sensors of interest\n",
    "sensor1 = 'ls5'\n",
    "sensor2 = 'ls7'\n",
    "sensor3 = 'ls8'\n",
    "\n",
    "#Group PQ by solar day to avoid idiosyncracies of N/S overlap differences in PQ algorithm performance\n",
    "pq_albers_product = dc.index.products.get_by_name(sensor1+'_pq_albers')\n",
    "valid_bit = pq_albers_product.measurements['pixelquality']['flags_definition']['contiguous']['bits']\n",
    "\n",
    "#load sensor specific band adjustment tuples for TSS and brightness\n",
    "brightness_coeff = {}\n",
    "brightness_coeff['ls5'] = (0.304, 0.279, 0.434, 0.559, 0.508, 0.186)\n",
    "brightness_coeff['ls7'] = (0.304, 0.279, 0.434, 0.559, 0.508, 0.186)\n",
    "#brightness_coeff['ls7'] = (0.3561, 0.3972, 0.3904, 0.6966, 0.2286, 0.1596)\n",
    "brightness_coeff['ls8'] = (0.3029, 0.2786, 0.4733, 0.5599, 0.508, 0.1872)\n",
    "\n",
    "greenness_coeff = {}\n",
    "greenness_coeff['ls5'] = (-0.285, -0.244, -0.544, 0.724, 0.084, -0.180)\n",
    "greenness_coeff['ls7'] = (-0.285, -0.244, -0.544, 0.724, 0.084, -0.180)\n",
    "#greenness_coeff['ls7'] = (-0.3344, -0.3544, -0.4556, 0.6966, -0.0242, -0.263)\n",
    "greenness_coeff['ls8'] = (-0.2941, -0.243, -0.5424, 0.7276, 0.0713, -0.1608)\n",
    "\n",
    "wetness_coeff = {}\n",
    "wetness_coeff['ls5'] = (0.151, 0.179, 0.330, 0.341, -0.711, -0.457)\n",
    "wetness_coeff['ls7'] = (0.151, 0.179, 0.330, 0.341, -0.711, -0.457)\n",
    "#wetness_coeff['ls7'] = (0.2626, 0.2141, 0.0926, 0.0656, -0.7629, -0.5388)\n",
    "wetness_coeff['ls8'] = (0.1511, 0.1973, 0.3283, 0.3407, -0.7117, -0.4559)\n",
    "\n",
    "tsm_coeff = {\n",
    "    'ls5': (3983, 1.6246),\n",
    "    'ls7': (3983, 1.6246),\n",
    "    'ls8': (3957, 1.6436)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Have a look at the dataframe of transects below to make sure it is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>descript</th>\n",
       "      <th>geometry</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Mouldy Crumpet to Joshua spring Nth Sth transect</td>\n",
       "      <td>LINESTRING (333358.6094532241 -2378083.7166778...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doongmabulla Springs 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Moses to Wobbly springs transect, includes sma...</td>\n",
       "      <td>LINESTRING (333420.8867547495 -2377528.8540737...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doongmabulla Springs 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Moses Springs transect</td>\n",
       "      <td>LINESTRING (333741.60005989 -2378101.391789466...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doongmabulla Springs 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Mouldy Crumpet to House springs across Carmich...</td>\n",
       "      <td>LINESTRING (331363.4966704529 -2377794.2407379...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doongmabulla Springs 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>House Springs - Carmichael River transect</td>\n",
       "      <td>LINESTRING (334086.5102908454 -2376836.1455913...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doongmabulla Springs 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>Follows Carmichael river from springs across c...</td>\n",
       "      <td>LINESTRING (331761.7087712438 -2374087.3671648...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clematis - Carmichael River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>Rewan Group subcrop area under Carmichael River</td>\n",
       "      <td>LINESTRING (340855.5085843539 -2378145.6934241...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rewan Group - Carmichael River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>Carmichael River transect through mine leases</td>\n",
       "      <td>LINESTRING (349388.9787330463 -2379960.5883129...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mine lease - Carmichael river</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>Carmichael river crossection just downstream o...</td>\n",
       "      <td>LINESTRING (359123.2453407632 -2381555.6643693...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carmichael River floodplain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>Joshua Springs - Carmichael River transect</td>\n",
       "      <td>LINESTRING (333750.8490890979 -2374947.4431831...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doongmabulla Springs 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LINESTRING (358006.8165333108 -2403375.6301288...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mellaluca Springs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>Transect just south of Carmichael</td>\n",
       "      <td>LINESTRING (358406.0937931376 -2392096.8069135...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Belyando River 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>Transect downstream of Carmicahael River</td>\n",
       "      <td>LINESTRING (375250.3853521309 -2351340.9583175...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Belyando River 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>Transect just downstream of Kevins Corner of s...</td>\n",
       "      <td>LINESTRING (358853.5869127007 -2465778.2461603...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Belyando River 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>Alpha Mine</td>\n",
       "      <td>LINESTRING (354339.6360460448 -2504297.6165467...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alpha test pit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>Just north of Alpha township, across Alpha Ck ...</td>\n",
       "      <td>LINESTRING (367634.7092069623 -2542941.8995852...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alpha Creek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>Just north of Alpha test pit across Sandy Cree...</td>\n",
       "      <td>LINESTRING (354022.5663817145 -2500112.5441448...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sandy Crk Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>Across Sandy Creek Valley</td>\n",
       "      <td>LINESTRING (344304.4962606996 -2526271.2159828...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>China First mine area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>Across Sandy Creek - Belyando River valleys</td>\n",
       "      <td>LINESTRING (371276.9506668684 -2479583.7323893...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Belyando River 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>transect across southern part of lake</td>\n",
       "      <td>LINESTRING (274062.0593882566 -2414172.5215990...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lake Galilee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>None</td>\n",
       "      <td>Main spring cluster</td>\n",
       "      <td>LINESTRING (246665.2421976388 -2446790.1498238...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Edgbaston Springs 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>None</td>\n",
       "      <td>Wetland area down gradient of main spring cluster</td>\n",
       "      <td>LINESTRING (246667.7440604525 -2450187.3304547...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Edgbaston  Springs 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>None</td>\n",
       "      <td>Also minor springs</td>\n",
       "      <td>LINESTRING (273958.1953697828 -2435977.0972836...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lake Dunn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>None</td>\n",
       "      <td>E -W section</td>\n",
       "      <td>LINESTRING (288096.6928568105 -2319682.8179906...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lake Buchanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>Transect upstream of springs on Moolayember Fm</td>\n",
       "      <td>LINESTRING (318850.0139154571 -2373787.1511299...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carmichael River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>Across Clematis outcrop, Carmichael River and ...</td>\n",
       "      <td>LINESTRING (338711.5808964549 -2378832.4134318...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doongmabulla Springs 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age                                           descript  \\\n",
       "0   None   Mouldy Crumpet to Joshua spring Nth Sth transect   \n",
       "1   None  Moses to Wobbly springs transect, includes sma...   \n",
       "2   None                             Moses Springs transect   \n",
       "3   None  Mouldy Crumpet to House springs across Carmich...   \n",
       "4   None          House Springs - Carmichael River transect   \n",
       "5   None  Follows Carmichael river from springs across c...   \n",
       "6   None    Rewan Group subcrop area under Carmichael River   \n",
       "7   None      Carmichael River transect through mine leases   \n",
       "8   None  Carmichael river crossection just downstream o...   \n",
       "9   None         Joshua Springs - Carmichael River transect   \n",
       "10  None                                               None   \n",
       "11  None                  Transect just south of Carmichael   \n",
       "12  None           Transect downstream of Carmicahael River   \n",
       "13  None  Transect just downstream of Kevins Corner of s...   \n",
       "14  None                                         Alpha Mine   \n",
       "15  None  Just north of Alpha township, across Alpha Ck ...   \n",
       "16  None  Just north of Alpha test pit across Sandy Cree...   \n",
       "17  None                          Across Sandy Creek Valley   \n",
       "18  None        Across Sandy Creek - Belyando River valleys   \n",
       "19  None              transect across southern part of lake   \n",
       "20  None                                Main spring cluster   \n",
       "21  None  Wetland area down gradient of main spring cluster   \n",
       "22  None                                 Also minor springs   \n",
       "23  None                                       E -W section   \n",
       "24  None     Transect upstream of springs on Moolayember Fm   \n",
       "25  None  Across Clematis outcrop, Carmichael River and ...   \n",
       "\n",
       "                                             geometry  length  \\\n",
       "0   LINESTRING (333358.6094532241 -2378083.7166778...     0.0   \n",
       "1   LINESTRING (333420.8867547495 -2377528.8540737...     0.0   \n",
       "2   LINESTRING (333741.60005989 -2378101.391789466...     0.0   \n",
       "3   LINESTRING (331363.4966704529 -2377794.2407379...     0.0   \n",
       "4   LINESTRING (334086.5102908454 -2376836.1455913...     0.0   \n",
       "5   LINESTRING (331761.7087712438 -2374087.3671648...     0.0   \n",
       "6   LINESTRING (340855.5085843539 -2378145.6934241...     0.0   \n",
       "7   LINESTRING (349388.9787330463 -2379960.5883129...     0.0   \n",
       "8   LINESTRING (359123.2453407632 -2381555.6643693...     0.0   \n",
       "9   LINESTRING (333750.8490890979 -2374947.4431831...     0.0   \n",
       "10  LINESTRING (358006.8165333108 -2403375.6301288...     0.0   \n",
       "11  LINESTRING (358406.0937931376 -2392096.8069135...     0.0   \n",
       "12  LINESTRING (375250.3853521309 -2351340.9583175...     0.0   \n",
       "13  LINESTRING (358853.5869127007 -2465778.2461603...     0.0   \n",
       "14  LINESTRING (354339.6360460448 -2504297.6165467...     0.0   \n",
       "15  LINESTRING (367634.7092069623 -2542941.8995852...     0.0   \n",
       "16  LINESTRING (354022.5663817145 -2500112.5441448...     0.0   \n",
       "17  LINESTRING (344304.4962606996 -2526271.2159828...     0.0   \n",
       "18  LINESTRING (371276.9506668684 -2479583.7323893...     0.0   \n",
       "19  LINESTRING (274062.0593882566 -2414172.5215990...     0.0   \n",
       "20  LINESTRING (246665.2421976388 -2446790.1498238...     0.0   \n",
       "21  LINESTRING (246667.7440604525 -2450187.3304547...     0.0   \n",
       "22  LINESTRING (273958.1953697828 -2435977.0972836...     0.0   \n",
       "23  LINESTRING (288096.6928568105 -2319682.8179906...     0.0   \n",
       "24  LINESTRING (318850.0139154571 -2373787.1511299...     0.0   \n",
       "25  LINESTRING (338711.5808964549 -2378832.4134318...     0.0   \n",
       "\n",
       "                              name  \n",
       "0           Doongmabulla Springs 1  \n",
       "1           Doongmabulla Springs 3  \n",
       "2           Doongmabulla Springs 2  \n",
       "3           Doongmabulla Springs 2  \n",
       "4           Doongmabulla Springs 4  \n",
       "5      Clematis - Carmichael River  \n",
       "6   Rewan Group - Carmichael River  \n",
       "7    mine lease - Carmichael river  \n",
       "8      Carmichael River floodplain  \n",
       "9           Doongmabulla Springs 5  \n",
       "10               Mellaluca Springs  \n",
       "11                Belyando River 1  \n",
       "12                Belyando River 2  \n",
       "13                Belyando River 3  \n",
       "14                  Alpha test pit  \n",
       "15                     Alpha Creek  \n",
       "16                Sandy Crk Valley  \n",
       "17           China First mine area  \n",
       "18                Belyando River 4  \n",
       "19                    Lake Galilee  \n",
       "20             Edgbaston Springs 1  \n",
       "21            Edgbaston  Springs 2  \n",
       "22                       Lake Dunn  \n",
       "23                   Lake Buchanan  \n",
       "24                Carmichael River  \n",
       "25          Doongmabulla Springs 5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transects_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop over transects, pull in rainfall and nbar from datacube and output hovmoller plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doongmabulla Springs 1 : Mouldy Crumpet to Joshua spring Nth Sth transect\n",
      "Doongmabulla_Springs_1_ix0\n",
      "loaded bom rainfall grids from datacube\n",
      "saved rainfall data to file\n"
     ]
    }
   ],
   "source": [
    "#i = 8  \n",
    "#use fiona module to open the shape file and iterate over the transects in the file.\n",
    "transects = fiona.open(transects_file)\n",
    "# while True:\n",
    "#     i = int(input(\"choose the index of the transect you would like to plot:\"))\n",
    "for i in range(len(transects)):\n",
    "    geom = shape(transects[i]['geometry'])\n",
    "    query = {\n",
    "        'time': (start_of_epoch, end_of_epoch),\n",
    "    }\n",
    "    query.update(geom_query(geom, geom_crs=transects.crs_wkt)) #comment this out if not using a polygon\n",
    "\n",
    "    #use the transect dataframe to get transect metadata\n",
    "    transect_index = transects_df.index[i]\n",
    "    transect_name = transects_df['name'][i] \n",
    "    if transects_df['descript'][i] is not None:\n",
    "        transect_description = transects_df['descript'][i]\n",
    "    else:\n",
    "        transect_description = ' '\n",
    "    try:\n",
    "        print(transect_name+' : '+transect_description)\n",
    "    except TypeError as err:\n",
    "        print(\"TypeError: {0}\".format(err))\n",
    "        print(transect_name)\n",
    "\n",
    "    #create a filename for the transect\n",
    "    shape_name = transect_name.split()\n",
    "    shape_name ='_'.join(shape_name)\n",
    "    shape_name=shape_name+'_ix'+str(transect_index)\n",
    "    print(shape_name)\n",
    "\n",
    "    #setup a save directory for our data\n",
    "    savepath ='/g/data/r78/rjd547/groundwater_activities/GalileeBasin/pickledata/'+shape_name+'/'\n",
    "    try:\n",
    "            os.mkdir(savepath)\n",
    "    except OSError as err:\n",
    "            print(\"OS error: {0}\".format(err))\n",
    "    try:\n",
    "        #try to get the rain data from a pickle file saved earlier \n",
    "        f = open(savepath+'Rainfall_data'+'.pkl', 'rb')\n",
    "        rain = pickle.load(f)\n",
    "        Studysite_rain = rain['Studysite_rain']\n",
    "        print('loaded rainfall grids from file:'+savepath+'Rainfall_data.pkl')\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        #Grab bom_rainfall_grids from the datacube\n",
    "        print('loaded bom rainfall grids from datacube')\n",
    "        Studysite_rain = dc.load(product = 'bom_rainfall_grids', **query)\n",
    "        #make a dictionary of the data we want to save\n",
    "        vars2pickle = {'Studysite_rain':Studysite_rain}\n",
    "        f = open(savepath+'Rainfall_data'+'.pkl', 'wb')\n",
    "        pickle.dump(vars2pickle,f) \n",
    "        print('saved rainfall data to file')\n",
    "        #pickle.dump(vars2pickle,f,protocol = 2, fix_imports = True) #maintain compatibility with python 2\n",
    "        f.close()   \n",
    "\n",
    "    #resample xarray Dataset Studysite_rain by Annual'AS' to get yearly avg with year starting in october\n",
    "    #Note that the resampling we did means that each year is labelled according to its first day  \n",
    "    rain_sp = Studysite_rain.mean(dim = ('latitude','longitude'))\n",
    "    month_sp = rain_sp.resample('MS', dim = 'time', how = 'mean')\n",
    "    year_avg = Studysite_rain.resample('AS-OCT', dim='time', how='mean', keep_attrs=True)\n",
    "    # Create a spatial average\n",
    "    year_avg_sp = year_avg.mean(dim = ('latitude', 'longitude'))\n",
    "\n",
    "    try:\n",
    "        #try to get the NBAR and PQ data for sensor n from a pickle file saved earlier\n",
    "        f = open(savepath+'NBARPQ_data'+'.pkl', 'rb')\n",
    "        NBPQdata = pickle.load(f)\n",
    "        sensor1_nbar = NBPQdata['sensor1_nbar']\n",
    "        sensor1_pq = NBPQdata['sensor1_pq']\n",
    "        sensor2_nbar = NBPQdata['sensor2_nbar']\n",
    "        sensor2_pq = NBPQdata['sensor2_pq']\n",
    "        sensor3_nbar = NBPQdata['sensor3_nbar']\n",
    "        sensor3_pq = NBPQdata['sensor3_pq']\n",
    "        print('loaded sensor NBAR and PQ from file')\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        #Retrieve the NBAR and PQ data for sensor n from the datacube\n",
    "        sensor1_nbar = dc.load(product= sensor1+'_nbar_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "        sensor1_pq = dc.load(product= sensor1+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)        \n",
    "        print('loaded sensor1 NBAR and PQ from datacube')\n",
    "\n",
    "        sensor2_nbar = dc.load(product= sensor2+'_nbar_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "        sensor2_pq = dc.load(product= sensor2+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)                  \n",
    "        print('loaded sensor2 NBAR and PQ from datacube')\n",
    "\n",
    "        sensor3_nbar = dc.load(product= sensor3+'_nbar_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "        sensor3_pq = dc.load(product= sensor3+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)                  \n",
    "        print('loaded sensor3 NBAR and PQ from datacube')\n",
    "\n",
    "        #make a dictionary of the data we want to save\n",
    "        pickle_vars = {'sensor1_nbar':sensor1_nbar,'sensor1_pq':sensor1_pq,\n",
    "                  'sensor2_nbar':sensor2_nbar,'sensor2_pq':sensor2_pq,\n",
    "                  'sensor3_nbar':sensor3_nbar,'sensor3_pq':sensor3_pq}\n",
    "\n",
    "        f = open(savepath+'NBARPQ_data'+'.pkl', 'wb')\n",
    "        pickle.dump(pickle_vars,f) \n",
    "        print('saved sensor NBAR and PQ data to file')\n",
    "        #pickle.dump(pickle_vars,f,protocol = 2, fix_imports = True) #maintain compatibility with python 2\n",
    "        f.close()\n",
    "\n",
    "        #save attributes\n",
    "        crs = sensor1_nbar.crs\n",
    "        crswkt = sensor1_nbar.crs.wkt\n",
    "        affine = sensor1_nbar.affine\n",
    "\n",
    "    s1_cloud_free = masking.make_mask(sensor1_pq, \n",
    "                                  cloud_acca='no_cloud',\n",
    "                                  cloud_shadow_acca = 'no_cloud_shadow',\n",
    "                                  cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                                  cloud_fmask='no_cloud',\n",
    "                                  blue_saturated = False,\n",
    "                                  green_saturated = False,\n",
    "                                  red_saturated = False,\n",
    "                                  nir_saturated = False,\n",
    "                                  swir1_saturated = False,\n",
    "                                  swir2_saturated = False,\n",
    "                                  contiguous=True)\n",
    "    s1_good_data = s1_cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor1_nbar = sensor1_nbar.where(s1_good_data)\n",
    "    sensor1_nbar.attrs['crs'] = crs\n",
    "    sensor1_nbar.attrs['affine'] = affine\n",
    "\n",
    "    s2_cloud_free = masking.make_mask(sensor2_pq, \n",
    "                                  cloud_acca='no_cloud',\n",
    "                                  cloud_shadow_acca = 'no_cloud_shadow',\n",
    "                                  cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                                  cloud_fmask='no_cloud',\n",
    "                                  blue_saturated = False,\n",
    "                                  green_saturated = False,\n",
    "                                  red_saturated = False,\n",
    "                                  nir_saturated = False,\n",
    "                                  swir1_saturated = False,\n",
    "                                  swir2_saturated = False,\n",
    "                                  contiguous=True)\n",
    "    s2_good_data = s2_cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor2_nbar = sensor2_nbar.where(s2_good_data)\n",
    "    sensor2_nbar.attrs['crs'] = crs\n",
    "    sensor2_nbar.attrs['affine'] = affine\n",
    "\n",
    "    #sensor 3 is commented out if the time period does not include landsat 8\n",
    "\n",
    "    s3_cloud_free = masking.make_mask(sensor3_pq, \n",
    "                                  cloud_acca='no_cloud',\n",
    "                                  cloud_shadow_acca = 'no_cloud_shadow',\n",
    "                                  cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                                  cloud_fmask='no_cloud',\n",
    "                                  blue_saturated = False,\n",
    "                                  green_saturated = False,\n",
    "                                  red_saturated = False,\n",
    "                                  nir_saturated = False,\n",
    "                                  swir1_saturated = False,\n",
    "                                  swir2_saturated = False,\n",
    "                                  contiguous=True)\n",
    "    s3_good_data = s3_cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor3_nbar = sensor3_nbar.where(s3_good_data)\n",
    "    sensor3_nbar.attrs['crs'] = crs\n",
    "    sensor3_nbar.attrs['affine'] = affine\n",
    "\n",
    "    #Set up some colour maps for the Hovmoller plots\n",
    "\n",
    "    #This controls the colour maps used for plotting NDVI, TSS and Normalised Burn Ratio\n",
    "    ndvi_cmap = mpl.colors.ListedColormap(['blue', '#ffcc66','#ffffcc' , '#ccff66' , '#2eb82e', '#009933' , '#006600'])\n",
    "    tss_cmap = mpl.colors.ListedColormap(['navy', 'blue', 'deepskyblue','aquamarine' , 'burlywood' , 'saddlebrown'])\n",
    "    #nbr_cmap = mpl.colors.ListedColormap(['darkslategray','dimgray' , 'lightgrey' , '#ccff66' , '#2eb82e', '#009933'])\n",
    "\n",
    "    ndvi_bounds = [-1, 0, 0.1, 0.25, 0.35, 0.5, 0.8, 1]\n",
    "    #nbr_bounds = [-1, -0.1, 0, 0.1, 0.2, 0.4, 0.6]\n",
    "    tss_bounds = [0, 10, 20, 50, 80, 100, 150]\n",
    "\n",
    "    tss_norm = mpl.colors.BoundaryNorm(tss_bounds, tss_cmap.N)\n",
    "    ndvi_norm = mpl.colors.BoundaryNorm(ndvi_bounds, ndvi_cmap.N)\n",
    "    #nbr_norm = mpl.colors.BoundaryNorm(nbr_bounds, nbr_cmap.N)\n",
    "\n",
    "    #Retrieve the hovmoller data volumes and concatenate them\n",
    "\n",
    "    geom_w = warp_geometry(geom, query['crs'], crs.wkt)\n",
    "    #have set this rather than the specific exact form of the query..\n",
    "    #warpy = {} #kludge \n",
    "    #warpy['crs'] = 'EPSG:3577'\n",
    "    #geom_w = warp_geometry(geom, warpy['crs'], crs.wkt)\n",
    "    hov_sensor1 = transect(sensor1_nbar, geom_w, 25)\n",
    "    hov_sensor2 = transect(sensor2_nbar, geom_w, 25)\n",
    "    hov_sensor3 = transect(sensor3_nbar, geom_w, 25)\n",
    "    #--------\n",
    "    #hov_multi = xr.concat([hov_sensor1, hov_sensor2], dim = 'time')\n",
    "    #hov_multi = hov_sensor1 #FIXME\n",
    "    hov_multi = xr.concat([hov_sensor1, hov_sensor2, hov_sensor3], dim = 'time')\n",
    "    time_sorted = hov_multi.time.argsort()\n",
    "    hov_multi = hov_multi.isel(time=time_sorted)\n",
    "\n",
    "    #print ('The number of time slices unfiltered = '+ str(hov_multi.time.size))\n",
    "    # Set the percentage of good data that you'd like to display with pernan variable - 0.9 will return rows that have 90%\n",
    "    # of valid values\n",
    "    pernan = 0.8\n",
    "    hov_multi = hov_multi.dropna('time',  thresh = int(pernan*hov_multi.distance.size))\n",
    "    #print ('The number of time slices filtered = '+str(hov_multi.time.size))\n",
    "\n",
    "    #Use this number to flag results as water or land (to be replaced with WOfS once available)\n",
    "    #this will throw a warning about nan comparison in xarray. \n",
    "    waterthresh = 500\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        hov_multi_land = hov_multi.where(hov_multi.swir1>waterthresh)\n",
    "        hov_multi_water = hov_multi.where(hov_multi.swir1<waterthresh)\n",
    "\n",
    "    hov_multi_ndvi = ((hov_multi.nir-hov_multi.red)/(hov_multi.nir+hov_multi.red))\n",
    "    hov_multi_nbr = ((hov_multi.nir-hov_multi.swir2)/(hov_multi.nir+hov_multi.swir2))\n",
    "    #NBR as defined in http://www.sciencedirect.com/science/article/pii/S0034425706005128\n",
    "    hov_multi_ndwi = ((hov_multi.nir-hov_multi.swir1)/(hov_multi.nir+hov_multi.swir1))\n",
    "    #NDWI as per http://www.sciencedirect.com/science/article/pii/S0034425703003353 and \n",
    "    #http://www.sciencedirect.com/science/article/pii/S0034425796000673\n",
    "\n",
    "    hov_multi_tsm = (tsm_coeff[sensor1][0]*((hov_multi_water.green + hov_multi_water.red)/20000)**tsm_coeff[sensor1][1])\n",
    "    #hov_multi_ndvi_drop = ((hov_multi_drop.nir-hov_multi.red)/(hov_multi_drop.nir+hov_multi.red))\n",
    "    hov_multi_ndvi_drop = hov_multi_ndvi.dropna('time',  thresh = int(pernan*hov_multi.distance.size))\n",
    "    \n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        #try plotting the first clean time slice to see where we are\n",
    "        print('transect image: ')\n",
    "        rgb = sensor1_nbar.isel(time =0).to_array(dim='color').sel(color=['swir1', 'nir', 'green']).transpose('y', 'x', 'color')\n",
    "        fake_saturation = 4500\n",
    "        clipped_visible = rgb.where(rgb<fake_saturation).fillna(fake_saturation)\n",
    "        max_val = clipped_visible.max(['y', 'x'])\n",
    "        scaled = (clipped_visible / max_val)\n",
    "        plt.imshow(scaled, interpolation = 'nearest',\n",
    "                   extent=[scaled.coords['x'].min(), scaled.coords['x'].max(), \n",
    "                           scaled.coords['y'].min(), scaled.coords['y'].max()])\n",
    "        ##turn this one on to see where the transect is on the image!\n",
    "        #plt.scatter(x=hov_sensor1.coords['x'], y=hov_sensor1.coords['y'], c='r')\n",
    "        plt.show()\n",
    "    \n",
    "    #Make a hovmoller plot and save it to file.\n",
    "    #Use firstyear and last year to zoom into periods of interest\n",
    "    firstyearhov = start_of_epoch#'1987-06-01'\n",
    "    lastyearhov = end_of_epoch #'2016-12-31'\n",
    "    fig = plt.figure(figsize=(11.27,11.69))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1,3])\n",
    "    ax1 = plt.subplot(gs[0, 0])\n",
    "    ax1.plot(month_sp.rainfall, month_sp.time, color='b', alpha = 1)\n",
    "    ax1.axes.set_xlabel('ave daily rainfall (mm): monthly (blue) yearly (grey)')\n",
    "    \n",
    "    #set up fill time as a datetime 64 object for matplotlib input\n",
    "    #set up variables to plot the fill behind the yearly rain data\n",
    "    filltime = (year_avg_sp.time.astype('datetime64'))\n",
    "    zeros = np.zeros(shape=(len(filltime)))\n",
    "    plt.fill_betweenx(filltime.time.values, zeros, year_avg_sp.rainfall, color ='k', alpha = 0.8)\n",
    "    #set up variables to plot the fill behind the months data\n",
    "    mzeros = np.zeros(shape=(len(month_sp.rainfall.time.values)))\n",
    "    plt.fill_betweenx(month_sp.rainfall.time.values, mzeros, month_sp.rainfall, color ='c', alpha = 1)\n",
    "    plt.axis([0, month_sp.rainfall.max(),lastyearhov , firstyearhov])\n",
    "    \n",
    "\n",
    "    ax2 = plt.subplot(gs[0, 1])\n",
    "    hov_multi_ndvi_drop.plot(x='distance', y='time', yincrease = False, cmap = ndvi_cmap, norm = ndvi_norm)\n",
    "    \n",
    "    #to turn total suspended matter off, comment out the following row:\n",
    "    \n",
    "    hov_multi_tsm.plot(x='distance', y='time', yincrease = False, cmap = tss_cmap, norm = tss_norm)\n",
    "    plt.axis([0, hov_multi_ndvi_drop.distance.max(), lastyearhov , firstyearhov])\n",
    "    ax2.set_anchor(\"SE\")\n",
    "\n",
    "    plt.suptitle(transect_name+' : '+transect_description, fontsize ='24')\n",
    "    #plt.show()\n",
    "    #save the output files!\n",
    "    plt.savefig(savepath+shape_name+'HovPlot'+'.png',bbox_inches='tight')\n",
    "\n",
    "    print (savepath)\n",
    "    \n",
    "    #make a dictionary of the data we want to save\n",
    "    vars2pickle = {'rain_sp':rain_sp, \n",
    "                   'month_sp':month_sp,\n",
    "                   'hov_multi':hov_multi,\n",
    "                   'hov_multi_ndvi_drop':hov_multi_ndvi_drop,\n",
    "                   'hov_multi_tsm':hov_multi_tsm, \n",
    "                   #'ts_multi_ndvi':ts_multi_ndvi, \n",
    "                   'ndvi_cmap': ndvi_cmap, \n",
    "                   'ndvi_norm': ndvi_norm, \n",
    "                   'tss_cmap': tss_cmap, \n",
    "                   'tss_norm': tss_norm, \n",
    "                   'savepath': savepath, \n",
    "                   'affine':affine}\n",
    "\n",
    "    #save the dictionary into a pickle file\n",
    "    f = open(savepath+'/Hov_plot_variables'+'.pkl', 'wb')\n",
    "    pickle.dump(vars2pickle,f) \n",
    "    f.close()\n",
    "    print()\n",
    "    # f=open(savepath+'/Hov_plot_variables'+'.pkl','rb')\n",
    "    # saved_vars = pickle.load(f)\n",
    "    # print(saved_vars.values())\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
